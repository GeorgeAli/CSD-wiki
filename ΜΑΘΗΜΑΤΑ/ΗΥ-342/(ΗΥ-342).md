# [(HY-342) Παράλληλος Προγραμματσμός](http://www.csd.uoc.gr/~hy342/)

## Ποιες διαφορες μεταξύ **Processes vs Threads**;
Processes | Threads
--- | ---
Processes are heavyweight operations |	Threads are lighter weight operations
Each process has its own memory space	 | Threads use the memory of the process they belong to
Inter-process communication is slow as processes have different memory addresses | Inter-thread communication can be faster than inter-process communication because threads of the same process share memory with the process they belong to
Context switching between processes is more expensive	| Context switching between threads of the same process is less expensive
Processes don’t share memory with other processes	| Threads share memory with other threads of the same process
 
## Τι είναι Map Reduce;
A **MapReduce** program is composed of a **map procedure** (*or method*), which performs **filtering and sorting** (*such as sorting students by first name into queues, one queue for each name*), and a **reduce method**, which performs a **summary operation** (*such as counting the number of students in each queue, yielding name frequencies*). The "MapReduce System" (also called "infrastructure" or "framework") orchestrates the processing by marshalling the distributed servers, running the various tasks in parallel, managing all communications and data transfers between the various parts of the system, and providing for redundancy and fault tolerance.

## Τι είναι Mutexes;
**Mutual exclusion** object (*mutex*) is a program object that allows multiple program threads to share the same resource, such as file access, but not simultaneously. It is a two state mechanism, of locks, whomever locks them must unlock them.

## Τι είναι Data Race;
Is the race between threads, who want to access the same data, but only one can at a time.

## Τι είναι Reader-Writer Locks;
**Readers–writer** (RW) or shared-exclusive lock is a synchronization primitive that solves one of the readers–writers problems*. An RW lock allows concurrent access for read-only operations, while write operations require exclusive access. This means that multiple threads can read the data in parallel but an exclusive lock is needed for writing or modifying data. When a writer is writing the data, all other writers or readers will be blocked until the writer is finished writing. A common use might be to control access to a data structure in memory that cannot be updated atomically and is invalid (and should not be read by another thread) until the update is complete.

## Ποιες και τι είναι Scheduling policies;
* Scheduling policies
> Scheduling is the method by which work specified by some means is assigned to resources that complete the work. The work may be virtual computation elements such as threads, processes or data flows, which are in turn scheduled onto hardware resources such as processors, network links or expansion cards.

* Scheduling disciplines
> Scheduling disciplines are algorithms used for distributing resources among parties which simultaneously and asynchronously request them.
> 1. First come, first served (FIFO)
> 2. Earliest deadline first
> 3. Shortest remaining time first[edit]
> 4. Fixed priority pre-emptive scheduling[edit]
> 5. Round-robin scheduling
> 6. Multilevel queue scheduling
> 7. Work-conserving schedulers
> 8. Scheduling optimization problems
> 9. Manual scheduling

## Τι είναι Priority Inversion;
In computer science, priority inversion is a problematic scenario in scheduling in which a high priority task is indirectly preempted by a lower priority task effectively "inverting" the relative priorities of the two tasks.

## Τι είναι Load Balancing;
Load balancing improves the distribution of workloads across multiple computing resources, such as computers, a computer cluster, network links, central processing units, or disk drives.

## Τι είναι Memoizing;
Memoization or memoisation is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again.

## Τι είναι Coherence;
Coherence: συνέπεια μεταξύ αντιγράφων της ίδιας
διεύθυνσης σε διαφορετικά σημεία της ιεραρχίας μνήμης.

## Τι είναι Consistency;
Consistency: σειρά με την οποία γίνονται όντως οι
εγγραφές στη μνήμη και σειρά με την οποία γίνονται αντιληπτές οι εγγραφές στη μνήμη από κάθε thread.
1. Sequential
1. Relaxed
1. Weak

## Τι είναι Data Race και πως προκαλείται και πως μπορούμε να το αποφύγουμε;
A data race occurs when **two or more threads in a single process access the same memory** location **concurrently**, and. **at least one of the accesses is for writing**, and the threads are not using any exclusive locks to control their accesses to that memory (Memory corruption).

Data races can be avoided by: <br>
> * execute functions seqeuncially
> * mutex
> * atomic

## Τι είναι Resource Contention;
**Resource contention** is a conflict over access to a shared resource such as random access memory, disk storage, cache memory, internal buses or external network devices. A resource experiencing ongoing contention can be described as oversubscribed.

## Τι είναι Load Balancing;
**Load balancing** improves the distribution of workloads across multiple computing resources, such as computers, a computer cluster, network links, central processing units, or disk drives.

## Τι είναι Lock Avoidance όταν χρησιμοποιούμε shared data;
Lock avoidance is a mechanism to access data without locking while still maintaining data integrity. It prohibits access to uncommitted data and serializes access to pages. Lock avoidance improves performance by reducing the overall volume of lock requests. After all, let’s face it, the most efficient lock is the one never taken.

## Ποια η διαφορά μεταξύ Concurrent και Parallel Programming;
* Concurrent Programming
> A concurrent program is **one** defining actions that may be performed "simultaneously", in the sense that more than one processes are running at the same time on the same hardware small amounts of quantum at a time, giving the perception of parallelism. 

* Parallel Programming
>	A parallel program is **one**, defining actions that may be performed **simultaneously**, in the sense that more than one threads are running at the same time on diffrent hardware, in a trully parallel manner. 

## Ποια η διαφορά του deadlock από το livelock;
* A deadlock is a state in which each member of a group is waiting for some other member to take action, such as sending a message or more commonly releasing a lock.
* A livelock is similar to a deadlock, except that the states of the processes involved in the livelock constantly change with regard to one another, none progressing.
> Both dead and live locks are stuck in a state they connot leave, but in a live lock, control flow and states are switched between parties, with no one progressing.

***

## Thread implementation in diffrent languages

programming language | positives | negatives
--- | --- | ---
pthreads | | 
openmp | | 
tbb | | 
java | | 
scala | | 

## Pthreads

### Example
```
#include <pthread.h>
#include <stdio.h>

/* this function is run by the second thread */
void *inc_x(void *x_void_ptr)
{

    /* increment x to 100 */
    int *x_ptr = (int *)x_void_ptr;
    while(++(*x_ptr) < 100);

    printf("x increment finished\n");

    /* the function must return something - NULL will do */
    return NULL;

}

int main()
{

    int x = 0, y = 0;

    /* show the initial values of x and y */
    printf("x: %d, y: %d\n", x, y);

    /* this variable is our reference to the second thread */
    pthread_t inc_x_thread;

    /* create a second thread which executes inc_x(&x) */
    if(pthread_create(&inc_x_thread, NULL, inc_x, &x)) {

    fprintf(stderr, "Error creating thread\n");
    return 1;

    }
    /* increment y to 100 in the first thread */
    while(++y < 100);

    printf("y increment finished\n");

    /* wait for the second thread to finish */
    if(pthread_join(inc_x_thread, NULL)) {

    fprintf(stderr, "Error joining thread\n");
    return 2;

    }

    /* show the results - x is now 100 thanks to the second thread */
    printf("x: %d, y: %d\n", x, y);

    return 0;

}
```

## OpenMP

### Ποες είναι οι ιδιότητες του OpenMP;
1. Parallel regions
> if under condition <br>
> num_threads

2. Work sharing

3. Synchronization

4. Data-sharing attribute
> private: Νέα μεταβλητή για κάθε thread <br>
> firstprivate: με αρχικοποίηση <br>
> lastprivate: μετά το region κρατά την τιμή που γράφτηκε
στο τελευταίο iteration <br>
> shared: Κοινή μνήμη, ο συγχρονισμός είναι ευθύνη του
προγραμματιστή <br>
> reduction: Η δομή reduction ορίζει πώς πολλά αντίγραφα μιας τοπικής μεταβλητής συνδυάζονται σε μία μεταβλητή που θα υπάρχει στο master thread στο τέλος <br>
> threadprivate: Νέα μεταβλητή για κάθε thread, δυναμική
δέσμευση, persistent <br>
> copyin: Αρχικοποίηση threadprivate <br>

### Ποες είναι οι μεταβλητές περιβάλλοντος του OpenMP;
1. Number of threads
1. Scheduling algorithm
1. Dynamic thread adjustment
1. Nested parallelism

### Ποες είναι οι run-time μεταβλητές του OpenMP;
1. Number of threads
1. Thread ID
1. Dynamic thread adjustment
1. Nested parallelism
1. Timers
1. API for locks, barriers

### Ποες είναι οι μορφές συγχρονισμού στο OpenMP;
1. critical: μόνο ένα thread κάθε φορά
1. atomic: μόνο για εγγραφή στη μνήμη
1. barrier: ραντεβού των threads του parallel section
1. ordered: περιορισμός στη σειρά
1. locks: low-level συγχρονισμός (όπως στα pthreads)
1. flush: μηχανισμός memory consistency

### Ποιοι είναι δύο τρόποι μεμονομένης εκτέλεσης κώδικα.
* single: Μόνο ένα thread θα εκτελέσει τον κώδικα.
* master: Μόνο το master thread θα εκτελέσει τον κώδικα.

### Ποια η διαφορά critical, atomic και single;
* Single specifies that a **section of code** should be executed by **single thread** (not necessarily the master thread)
* Critical specifies that code is executed by one **thread at a time**.
> So the former will be executed only once while the later will be executed as many times as there are of threads.
* Atomic specifies that one operation will executed faster, due to harware implementation of atomic.

### Ποια είναι τα scheduling policies του OpenMP;
1. schedule(static[, chunk]):
1. schedule(dynamic[, chunk]):
1. schedule(guided[, chunk]):
1. schedule(runtime):

### Τι είναι OpenMP Flush;
If executed like so:
```
#pragma omp flush [(var)]  
```
Specifies that all threads have the same view of memory for all shared objects.

### Τι είναι OpenMP Tasks;
Ανεξάρτητα κομμάτια δουλειάς
* Κώδικας
* Δεδομένα
* Control variables
Τα tasks εκτελούνται από threads
Το runtime system του OpenMP αποφασίζει την αντιστοίχηση

### Example
```
#pragma omp parallel {
    #pragma omp for
        for (...) 
}

#pragma omp parallel {
    #pragma omp for
    for (...) 
}
```

## TBB 

### Ποια είναι τα πλεονεκτήματα του TBB;
1. Λογικός παραλληλισμός αντί για threads
1. Παραλληλισμός για ταχύτητα 
1. Συμβατότητα με άλλες μορφές threading
1. Έμφαση σε data parallelism
1. Generics (templates)
1. Έτοιμα patterns παραλληλισμού

### Ποια είναι τα μειονεκτήματα του TBB;
1. Όχι για παραλληλισμό I/O
1. Όχι για real-time εφαρμογές
> “unfair” εκτέλεση των διαθέσιμων tasks, για λόγους βελτιστοποίησης στις caches
1. Βιβλιοθήκη – Θέματα compilation

### Ποιες είναι οι δομές παραλληλισμού του TBB;
#### Parallel Algorithms
* parallel_for
* parallel_for_each
* parallel_reduce
* parallel_do
* ...
#### Flow Graph
* data flow
* functional nodes, buffering nodes, split/join nodes, ...
#### Ranges, Partitioners
* Περιγραφή κατανομής δεδομένων
#### Tasks, Task groups
* Γενικός tasking παραλληλισμός
#### Task scheduler
* Επιλογή προτεραιοτήτων, κλπ.
#### Synchronization primitives
* atomic operations
* mutexes
* rw_mutexes

### Γράψτε ποιές είναι οι δομές παραλληλισμου και τι κάνουν.
* parallel_for, parallel_for_each:
> Παράλληλη εκτέλεση βρόχων με ανεξάρτητα iterations
* parallel_reduce:
> Παράλληλη εκτέλεση βρόχων με ανεξάρτητα iterations που στο τέλος συνδυάζουν τα αποτελέσματά τους 
* parallel_scan:
> Υπολογισμός του parallel prefix 
* parallel_pipeline:
> Παράλληλο pipeline που δημιουργείται από σειριακά και παράλληλα κομμάτια
* parallel_do:
> Παράλληλη εκτέλεση βρόχων με ανεξάρτητα iterations
όπου μπορεί να προκύψουν νέα iterations κατά την εκτέλεση
* parallel_sort:
> Παράλληλη ταξινόμηση
* parallel_invoke:
> Παράλληλη εκτέλεση γενικών συναρτήσεων μέσω function objects ή function pointers που δεν μπορούν να δέχονται ή να επιστρέφουν τιμές.

### Τι είναι το Granularity του TBB;
Granularity refers to the breakinf down of larger tasks into smaller ones, more finely delegated tasks, grain-size being the number of iterations for a "reasonable size" chunk to deal out to a processor.

### Τι είναι το Tasks και τα Task Groups του TBB;
Are TBB units of work, are made to be scheduled and executed per thread. Task Groups are a way to categorize certain tasks, and group them together. Every group has diffrent 

### Τι είναι τα Παράλληλα Containers του TBB;
* Fine-grain συγχρονισμός
* Χαμηλότερη απόδοση σε σειριακή χρήση
* Καλύτερη κλιμακωσιμότητα σε παράλληλο κώδικα
* Δεν χρειάζονται τον TBB scheduler
* Συμβατά με pthreads, OpenMP

### Ποιοι είναι οι TBB Memory Allocators και τι πεοσφέρουν;
TBB provides two memory allocator templates, the scalable_allocator<T> and cache_aligned_allocator<T>. They address critical issues in parallel programming: scalability and false sharing.
1. Scalable Memory Allocator
> Problems of scalability arise when using memory allocators originally designed for serial programs on multiple threads.  In some of these allocators, threads must compete for access to a single shared pool in a way that allows only one thread to allocate at a time. Use the memory allocator template scalable_allocator<T> avoids such scalability bottlenecks. This template can improve the performance of programs that rapidly allocate and free memory. <br>
2. Cache Aligned Allocator
> Problems of false sharing arise when two threads access different words that share the same cache line. The problem is that a cache line is the unit of information interchange between processor caches. If one processor modifies a cache line and another processor reads (or writes) the same cache line, the cache line must be moved from one processor to the other, even if the two processors are dealing with different words within the line. False sharing can hurt performance because cache lines can take hundreds of clocks to move.  Use the class cache_aligned_allocator<T> to always allocate on a cache line. Two objects allocated by cache_aligned_allocator are guaranteed to not have false sharing. <br>
 
### Τι είναι το Data Flow Graph το TBB;
* Μερικές εφαρμογές εκφράζονται ως κόμβοι γράφου που ανταλλάζουν μηνύματα
* Reactive προγραμματισμός: event → response
* Task graph, πολύπλοκες σχέσεις μεταξύ tasks
* Εφαρμογές actor-based, κόμβοι actors που αντιδρούν στο περιβάλλον 
* κλπ

### Ποια είναι τα είδη κόμβων στο Flow Graph το TBB;
1. Functional: εκτελούν μια λειτουργία
1. Buffering: λειτουργία αποθήκευσης δεδομένων
1. Split/Join: συνδυασμός αποτελεσμάτων διαφορετικών μονοπατιών στο γράφο, ή δημιουργία μονοπατιών
1. Other
 
### Ποια είναι τα είδη mutexes που υποστηρίζει το TBB;
Mutex | Scalable | Fair | Recursive | Long Wait | Size
--- | --- | --- | --- | --- | --- 
mutex| OS dependent| OS dependent| no| blocks| ≥ 3 words |
recursive_mutex |OS dependent |OS dependent |✓ |blocks |≥ 3 words
spin_mutex |no |no |no |yields |1 byte
speculative_spin_mutex | HW dependent | no | no | yields | 2 cache lines
queuing_mutex | ✓ | ✓ | no | yields | 1 word
spin_rw_mutex | no | no | no | yields | 1 word
speculative_spin_rw_mutex | HW dependent | no | no | yields | 3 cache lines
queuing_rw_mutex | ✓ | ✓ | no | yields | 1 word
null_mutex | moot | ✓ | ✓ | never | empty
null_rw_mutex | moot | ✓ | ✓ | never | empty

### Τι είναι τα [ ] στα lamdas στο TBB;
* captures	~	a comma-separated list of zero or more captures, optionally beginning with a capture-default. <br>
Capture list can be passed as follows (see below for the detailed description): <br>
[a,&b] where a is captured by copy and b is captured by reference. <br>
[this] captures the current object (*this) by reference <br>
[&] captures all automatic variables used in the body of the lambda by reference and current object by reference if exists <br>
[=] captures all automatic variables used in the body of the lambda by copy and current object by reference if exists <br>
[ ] captures nothing <br>

## Java Threads

### Ποια είναι τα πλεονεκτήματα των Threads;
1. Τα threads μπορούν να αυξήσουν την ταχύτητα
1. Φυσικό για πολλά προγραμματιστικά μοντέλα

### Ποια είναι τα μειονεκτήματα των Threads;
1. Μειονεκτήματα: Αυξημένη πολυπλοκότητα
1. Αυξημένη χρήση πόρων
 
### Τι είναι τα alarms στη Java;
Είναι ένα thread το οποίο κάνει trigger μετά από τον επιθυμητό χρόνο.
 
### Τι είναι το Synchronize στη Java;
Χρήση του synchronized keyword για ορισμό μιας μεθόδου ως synchronized
* Το ίδιο με συγχρονισμό πάνω στο lock του αντικειμένου this στον κώδικα της μεθόδου
* Ευκολότερο να εκφραστεί το ίδιο pattern

### Τι είναι το static synchronize στη Java;
In general, synchronized methods are used to protect access to resources that are accessed concurrently. When a resource that is being accessed concurrently belongs to each instance of your class, you use a synchronized instance method; when the resource belongs to all instances (i.e. when it is in a static variable) then you use a synchronized static method to access it.

### Ποιο είναι το Lifecycle των threads στη Java;
1. **New**: *Δημιουργήθηκε αλλά δεν άρχισε ακόμη*
1. **Running**: *Εκτελείται αυτή τη στιγμή ή μπορεί να εκτελεστεί σε οποιοδήποτε ελεύθερο CPU core*
1. **Runnable/Blocked**: *Περιμένει για I/O, lock, ή κάποιο άλλο synchronization operation*
1. **Sleeping**: *Paused για κάποιο διάστημα καθορισμένο από τον προγραμματιστή*
1. **Terminated**: *Έχει τελειώσει, δεν εκτελείται*

### Ποια είναι τα condition interfaces και τι κάνει το καθένα;
* **await()** : *Causes the current thread to wait until it is signalled or interrupted.*
* **await(t, u)** : *Causes the current thread to wait until it is signalled or interrupted, or the specified waiting time elapses.*
* **signal()** : *Wakes up one waiting thread.*
* **signalall()** : *Wakes up all waiting threads.*
